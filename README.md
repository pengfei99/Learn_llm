# Learn llms

Today, we hear a lot about **large language models (LLMs)** like GPT-3, GPT-4, PaLM, Gopher, etc. These models have 
shown their capacity to solve problems and generate text. However, these LLMs are not open source, which makes it 
difficult to understand how they work and to identify any potential biases ðŸ˜¥. This is where 
`LLaMA (Large Language Model Meta AI)` comes in.

`LLaMA is a family of LLMs developed by Meta AI and has four model sizes: 7, 13, 33, and 65 billion parameters`. 
It is designed to help researchers advance their work in this subfield of AI. It can be used for a variety of 
tasks like text generation, translation, question answering, code generation, and Summarization. Itâ€™s currently 
supported on Linux, MacOS, and Windows, and has bindings available for Python, C#, Java, Go, and more.

In this repo, we will learn:
- the basics of LLM models
- How to deploy a LLM model/and query it
- How to retrain a LLM model
- How to use a LLM model in a real world application


https://docs.privategpt.dev/installation

https://github.com/abetlen/llama-cpp-python
